{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------EXTRACTION---------------\n",
      "\n",
      "Extracting data/training_images...\n",
      "Extracting data/test_images...\n",
      "Extracting data/training_labels...\n",
      "Extracting data/test_labels...\n",
      "Files extraction: OK\n",
      "Loading dataset: OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------PREPROCESSING--------------\n",
      "\n",
      "Resize dataset: OK\n",
      "One-Hot-Encoding: OK\n",
      "Train and Validation set split: OK\n",
      "\n",
      "----------------TRAINING-----------------\n",
      "\n",
      "EPOCHS: 15\n",
      "BATCH_SIZE: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 12.270877 | train-acc: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 2: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 10.318600 | train-acc: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 8.832342 | train-acc: 0.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 7.385984 | train-acc: 0.550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 5: 100%|██████████| 2/2 [00:01<00:00,  1.02s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 5.995745 | train-acc: 0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 6: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 4.595350 | train-acc: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 7: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 3.320626 | train-acc: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 8: 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 2.321850 | train-acc: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 9: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-loss: 1.562362 | train-acc: 0.980\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "filename = [\n",
    "        [\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "        [\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "        [\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "        [\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def toy_train():\n",
    "    print(\"\\n----------------EXTRACTION---------------\\n\")\n",
    "    X, y, X_test, y_test = load(filename)\n",
    "    X, X_test = X/float(255), X_test/float(255)\n",
    "    X -= np.mean(X)\n",
    "    X_test -= np.mean(X_test)\n",
    "    \n",
    "    # X = (X - np.mean(X))/ np.std(X)\n",
    "    # X_test = (X_test - np.mean(X_test))/ np.std(X_test)\n",
    "\n",
    "    val = 100\n",
    "\n",
    "    X = X[:val, ...]\n",
    "    y = y[:val, ...] \n",
    "\n",
    "    print(\"\\n--------------PREPROCESSING--------------\\n\")\n",
    "    \n",
    "    #X = resize_dataset(X)\n",
    "    print(\"Resize dataset: OK\")\n",
    "    y = one_hot_encoding(y)\n",
    "    print(\"One-Hot-Encoding: OK\")\n",
    "    X_train, y_train, _, _ = train_val_split(X, y)\n",
    "    print(\"Train and Validation set split: OK\\n\")\n",
    "    \n",
    "    model = ToyModel()\n",
    "    cost = CrossEntropyLoss()\n",
    "    params = model.get_params()\n",
    "\n",
    "    optimizer = AdamGD(lr = 0.001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, params = model.get_params())    \n",
    "    #optimizer = SGD(lr=0.01, params=model.get_params())\n",
    "    train_costs, val_costs = [], []\n",
    "    \n",
    "    print(\"----------------TRAINING-----------------\\n\")\n",
    "\n",
    "    NB_EPOCH = 15\n",
    "    BATCH_SIZE = val//2\n",
    "\n",
    "    print(\"EPOCHS: {}\".format(NB_EPOCH))\n",
    "    print(\"BATCH_SIZE: {}\".format(BATCH_SIZE))\n",
    "    print()\n",
    "\n",
    "    nb_train_examples = len(X_train)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(NB_EPOCH):\n",
    "\n",
    "        #-------------------------------------------------------------------------------\n",
    "        #                                       \n",
    "        #                               TRAINING PART\n",
    "        #\n",
    "        #-------------------------------------------------------------------------------\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0 \n",
    "\n",
    "        pbar = trange(nb_train_examples // BATCH_SIZE)\n",
    "        train_loader = dataloader(X_train, y_train, BATCH_SIZE)\n",
    "\n",
    "        for i, (X_batch, y_batch) in zip(pbar, train_loader):\n",
    "\n",
    "            y_pred = model.forward(X_batch)\n",
    "            loss, deltaL = cost.get(y_pred, y_batch)\n",
    "\n",
    "            grads = model.backward(deltaL)\n",
    "            params = optimizer.update_params(grads)\n",
    "            model.set_params(params)\n",
    "\n",
    "            train_loss += loss * BATCH_SIZE\n",
    "            train_acc += sum((np.argmax(y_batch, axis=1) == np.argmax(y_pred, axis=1)))\n",
    "         \n",
    "            pbar.set_description(\"[Train] Epoch {}\".format(epoch+1))\n",
    "        \n",
    "        train_loss /= nb_train_examples\n",
    "        train_costs.append(train_loss)\n",
    "        train_acc /= nb_train_examples\n",
    "\n",
    "        info_train = \"train-loss: {:0.6f} | train-acc: {:0.3f}\"\n",
    "        print(info_train.format(train_loss, train_acc))\n",
    "        \n",
    "    pbar.close()\n",
    "\n",
    "toy_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
